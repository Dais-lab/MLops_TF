{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kernel for someone want to deep dive into image classification. I use CNN for classification model. If you found this Kernel helpful please up vote it. If you have some feedback and question don't forget to comment below. \n",
    "\n",
    "I have simplier model with \n",
    "* https://www.kaggle.com/uysimty/get-start-image-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe76d1d1ded592430e7548feacfa38dc42f085d9"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 06:35:40.317461: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 06:35:40.437525: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator # 이미지 데이터의 배치를 생성, 이미지 전처리에 사용\n",
    "from keras.utils import to_categorical # 여러 개의 Y값을 0과 1로만 이루어진 형태로 바꿔주는 one-hot-encoding\n",
    "from sklearn.model_selection import train_test_split # scikit-learn 패키지 중 model_selection에 데이터 분할을 위한 train_test_split 함수가 있음.\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os # os.listdir을 쓰기 위해서\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [(\"User-agent\", \"Mozilla/5.0\")]\n",
    "urllib.request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_RUN = False # 아래에 사용됨\n",
    "IMAGE_WIDTH=128 # 이미지 넓이(행)\n",
    "IMAGE_HEIGHT=128 # 이미지 높이(열)\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3 # 이미지 channel(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 256\n",
    "CLASSES = 2\n",
    "EPOCHS = 7\n",
    "N_TRAIN_EXAMPLES = 3000\n",
    "STEPS_PER_EPOCH = int(N_TRAIN_EXAMPLES / BATCHSIZE)\n",
    "VALIDATION_STEPS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global train_df\n",
    "global validate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7335a579cc0268fba5d34d6f7558f33c187eedb3"
   },
   "source": [
    "# Prepare Traning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"data/train\") # os.listdir은 디렉토리 내에 있는 모든 파일 및 디렉토리 리스트를 가져와서 indexing 한다.\n",
    "categories = [] # 빈 list 한 개 만든다.\n",
    "for filename in filenames:              # filenames에 있는 list들을 한 개씩 받아온다.                       \n",
    "    category = filename.split('.')[0]   # . 을 기준으로 나누고, '0'위치에 있는 것을 category 변수에 저장\n",
    "    if category == 'dog':\n",
    "        categories.append(1) # 강아지이면 1을 넣고 (append : 덧붙이다)\n",
    "    else:\n",
    "        categories.append(0) # 강아지가 아니면(고양이면) 0을 넣어라\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "}) # 데이터프레임 만들기 -  filename이라는 col에 filenames value 넣기, category라는 col에 categories value 넣기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification. \n",
    "\n",
    "So we will convert 1 to dog and 0 to cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})\n",
    "\n",
    "# replace를 이용해서 0은 cat으로 1은 dog로 바꿔라.\n",
    "# 이유: image generator를 사용할 것이기 때문이고,\n",
    "#       image generator는 classification에 적합한 one-hot encoding을 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.5446.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.7408.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog.24.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.10010.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.12418.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename category\n",
       "0   cat.5446.jpg      cat\n",
       "1   cat.7408.jpg      cat\n",
       "2     dog.24.jpg      dog\n",
       "3  cat.10010.jpg      cat\n",
       "4  cat.12418.jpg      cat"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # category 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef"
   },
   "outputs": [],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "# df: 분할시킬 data (DataFrame)\n",
    "# test_size: test dataset의 비율이나 갯수(default=0.25) -> 여기서는 validation set이라 할 수 있다.\n",
    "# random state: 데이터 분할시 셔플이 이루어지는데 이를 위한 시드값\n",
    "# shuffle: 셔플여부설정 (default=True)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True) # index를 reset함 -> drop: index로 세팅한 열을 데이터프레임내에서 삭제할지 여부를 결정한다.\n",
    "validate_df = validate_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "ae3dec0361f0443132d0309d3b883ee80070cf9f"
   },
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "# 제가 뭔지 확인해 본거에요.\n",
    "print(train_df.shape) \n",
    "print(validate_df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff760be9104f7d9492467b8d9d3405011aa77d11"
   },
   "source": [
    "# Traning Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset(train_df):\n",
    "    # 신경망 모델의 성능을 높이기 위한 위한 \"데이터 부풀리기(Data augmentation)\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=15,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "    # rotation_range : 지정된 각도 \"범위\"내에서 임의로 원본이미지를 회전시킨다. // 단위:(도) -> 여기서는 15니까, 0도에서 15도 사이\n",
    "    # rescale : byte와 관련이 있는듯 255라는 숫자가\n",
    "    # shear_range : 밀림 강도 범위내에서 임의로 원본이미지를 변형시킴\n",
    "\n",
    "    # zoom_range : 지정된 확대/축소 범위내에서 임의로 원본이미지를 확대/축소. “1 - 수치”부터 “1 + 수치”사이 범위로 확대/축소.\n",
    "    #              예를 들어 0.2이라면, 0.8배에서 1.2배 크기 변화를 시킵니다.\n",
    "\n",
    "    # horizontal_flip : 수평방향으로 뒤집느냐 마느냐\n",
    "\n",
    "    # width_shift_range : 지정된 \"수평방향\" 이동 범위내에서 임의로 원본이미지를 이동시킴. 수치는 \"전체 넓이\"의 비율(실수)로 나타냄.\n",
    "    #                     예를 들어 0.1이고 전체 넓이가 100이면, 10픽셀 내외로 \"좌우\" 이동.\n",
    "\n",
    "    # height_shift_range : 지정된 \"수직방향\" 이동 범위내에서 임의로 원본이미지를 이동시킴. 수치는 \"전체 높이\"의 비율(실수)로 나타냄..\n",
    "    #                       예를 들어 0.1이고 전체 높이가 100이면, 10픽셀 내외로 \"상하\" 이동.\n",
    "\n",
    "\n",
    "    # 'dataframe'과 '디렉토리'의 위치를 전달받아 증강/정규화된 데이터의 \"배치\"를 생성.\n",
    "    train_generator = train_datagen.flow_from_dataframe( \n",
    "        train_df, # DataFrame (전체 중에 80%만 있음)\n",
    "        \"data/train/\", # 문자열, 이미지를 읽을 '디렉토리'의 경로 (전체 data가 있음) \n",
    "        x_col='filename', # train_df 데이터프레임에 filename col의 값들을 가져옴\n",
    "        y_col='category', # train_df 데이터프레임에 category col의 값들을 가져옴\n",
    "        target_size=IMAGE_SIZE, # \n",
    "        class_mode='categorical', # 2D numpy array of one-hot encoded labels. Supports multi-label output.\n",
    "        batch_size=batch_size # batch size\n",
    "    )\n",
    "    return train_generator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x7fbd043c65e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = train_dataset(train_df)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "859c7b2857939c19fd2e3bb32839c9f7deb5aa3f"
   },
   "source": [
    "### Validation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset(validate_df):\n",
    "    # 위에 train_datagen과는 다르게 rescale만 해줌. (검증하는 거니까!)\n",
    "    # rescale 하는 이유: 정규화 과정임. image가 0~255까지 값을 가지는 2차원 배열인데, 0~255 사이의 값을\n",
    "    #                   0.0과 1.0사이의 값으로 바꾸기 위함이다.\n",
    "    #                   활성화함수 및 오류역전파 알고리즘은 0.0과 1.0사이의 값을 좋아하기 때문이다.\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # 위에 있는 train_generator와 같다\n",
    "    validation_generator = validation_datagen.flow_from_dataframe(\n",
    "        validate_df, \n",
    "        \"data/train/\", \n",
    "        x_col='filename',\n",
    "        y_col='category',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        class_mode='categorical',\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    return validation_generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DataFrameIterator at 0x7fbd043c66a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_ds = validate_dataset(validate_df)\n",
    "validate_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "810ddf1373d9db470ed48da4f30ca5a6c1274435"
   },
   "source": [
    "Seem to be nice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Input Layer**: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n",
    "* **Conv Layer**: This layer will extract features from image.\n",
    "* **Pooling Layer**: This layerreduce the spatial volume of input image after convolution.\n",
    "* **Fully Connected Layer**: It connect the network from a layer to another layer\n",
    "* **Output Layer**: It is the predicted values layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "def create_model(trial):\n",
    "    # Hyperparameters to be tuned by Optuna.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
    "    units = trial.suggest_categorical(\"units\", [32, 64, 128, 256, 512])\n",
    "    \n",
    "    conv_base = VGG16(weights='imagenet',\n",
    "                    include_top=False,\n",
    "                    input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS))\n",
    "\n",
    "    model = tf.keras.Sequential() # 가장 자주 사용하는 구조인 층을 순서대로 쌓아 올린 네트워크{keras 사용 - 모델을 정의(생성)}\n",
    "    conv_base.trainable = False  # Freeze weights of conv_base layers (VGG16)\n",
    "\n",
    "    # Convolution\n",
    "    # 인공신경망 모델을 효율적으로 학습시키기 윈한 개선 방법들 (BatchNormalization, Dropout, ModelEnsemble)\n",
    "    model.add(conv_base)\n",
    "    model.add(tf.keras.layers.Flatten()) # - 이 층에는 학습되는 가중치가 없고 데이터를 변환하기만 한다.(1차원 vector으로 바꿈)\n",
    "                        # - 이 층은 하나의 layer에 있는 모든 neuron을 또 다른 layer의 모든 neuron과 연결 시켜준다.\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu')) # dense로 층을 쌓음 - 첫번째 Dense층은 512개의 노드를 가짐\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='softmax')) # 2: because we have cat and dog classes\n",
    "                                            # 마지막 층은 2개의 노드의 소프트맥스층 : 이 층은 2개의 확률을 반환하고 반환된 값의 전체 합은 1이다. \n",
    "                                            # 각 노드는 현재 이미지가 2개 클래스 중 하나에 속할 확률을 출력\n",
    "\n",
    "\n",
    "    # # Compose neural network with one hidden layer.\n",
    "    # model = tf.keras.Sequential()\n",
    "    # model.add(tf.keras.layers.Flatten())\n",
    "    # model.add(tf.keras.layers.Dense(units=units, activation=tf.nn.relu))\n",
    "    # model.add(tf.keras.layers.Dense(CLASSES, activation=tf.nn.softmax))\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(\n",
    "            learning_rate=learning_rate, momentum=momentum, nesterov=True\n",
    "        ),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global train_df\n",
    "    global validate_df\n",
    "    # Clear clutter from previous TensorFlow graphs.\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    # Metrics to be monitored by Optuna.\n",
    "    if tf.__version__ >= \"2\":\n",
    "        monitor = \"val_accuracy\"\n",
    "    else:\n",
    "        monitor = \"val_acc\"\n",
    "\n",
    "    # Create tf.keras model instance.\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # Create dataset instance.\n",
    "    ds_train = train_dataset(train_df)\n",
    "    ds_eval = validate_dataset(validate_df)\n",
    "\n",
    "    # Create callbacks for early stopping and pruning.\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "        TFKerasPruningCallback(trial, monitor),\n",
    "    ]\n",
    "\n",
    "    # Train model.\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "        validation_data=ds_eval,\n",
    "        validation_steps=VALIDATION_STEPS,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    return history.history[monitor][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(study):\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        direction=\"maximize\", pruner=optuna.pruners.MedianPruner(n_startup_trials=2)\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=25, timeout=600)\n",
    "\n",
    "    show_result(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:35:46,750]\u001b[0m A new study created in memory with name: no-name-b35c8304-bac5-46e4-bdc1-1f5242be6c80\u001b[0m\n",
      "2023-01-07 06:35:46.851512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 06:35:47.445427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22284 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 06:35:50.164972: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-01-07 06:35:52.142144: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-01-07 06:35:52.145813: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fb9a0014520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-07 06:35:52.145866: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-01-07 06:35:52.229340: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 162ms/step - loss: 0.8147 - accuracy: 0.6667 - val_loss: 0.5479 - val_accuracy: 0.7156\n",
      "Epoch 2/7\n",
      "11/11 [==============================] - 2s 159ms/step - loss: 0.6672 - accuracy: 0.7576 - val_loss: 0.4516 - val_accuracy: 0.7667\n",
      "Epoch 3/7\n",
      "11/11 [==============================] - 2s 158ms/step - loss: 0.6736 - accuracy: 0.7394 - val_loss: 0.3787 - val_accuracy: 0.8467\n",
      "Epoch 4/7\n",
      "11/11 [==============================] - 2s 148ms/step - loss: 0.6333 - accuracy: 0.7333 - val_loss: 0.7870 - val_accuracy: 0.6422\n",
      "Epoch 5/7\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 0.5996 - accuracy: 0.7273 - val_loss: 1.0292 - val_accuracy: 0.5733\n",
      "Epoch 6/7\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 0.6116 - accuracy: 0.7333 - val_loss: 0.8610 - val_accuracy: 0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:02,556]\u001b[0m Trial 0 finished with value: 0.6422222256660461 and parameters: {'learning_rate': 0.010146995548684241, 'momentum': 0.17612938714458037, 'units': 128}. Best is trial 0 with value: 0.6422222256660461.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - 3s 167ms/step - loss: 1.0016 - accuracy: 0.5758 - val_loss: 1.2946 - val_accuracy: 0.4978\n",
      "Epoch 2/7\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 0.6598 - accuracy: 0.7333 - val_loss: 1.9029 - val_accuracy: 0.4867\n",
      "Epoch 3/7\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 0.5670 - accuracy: 0.7576 - val_loss: 1.7414 - val_accuracy: 0.5111\n",
      "Epoch 4/7\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.5296 - accuracy: 0.7758 - val_loss: 1.0399 - val_accuracy: 0.5533\n",
      "Epoch 5/7\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 0.5593 - accuracy: 0.7818 - val_loss: 0.4816 - val_accuracy: 0.7644\n",
      "Epoch 6/7\n",
      "11/11 [==============================] - 2s 155ms/step - loss: 0.4921 - accuracy: 0.8061 - val_loss: 0.5105 - val_accuracy: 0.7356\n",
      "Epoch 7/7\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 0.5214 - accuracy: 0.7879 - val_loss: 0.4960 - val_accuracy: 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:15,858]\u001b[0m Trial 1 finished with value: 0.7644444704055786 and parameters: {'learning_rate': 0.0021728763054050934, 'momentum': 0.7006986038340426, 'units': 512}. Best is trial 1 with value: 0.7644444704055786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1498 - accuracy: 0.6121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:19,329]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - 3s 175ms/step - loss: 0.8851 - accuracy: 0.5818 - val_loss: 0.5903 - val_accuracy: 0.6844\n",
      "Epoch 2/7\n",
      "11/11 [==============================] - 2s 149ms/step - loss: 0.8029 - accuracy: 0.6970 - val_loss: 0.6517 - val_accuracy: 0.6578\n",
      "Epoch 3/7\n",
      "11/11 [==============================] - 2s 150ms/step - loss: 0.8794 - accuracy: 0.6970 - val_loss: 0.4881 - val_accuracy: 0.7867\n",
      "Epoch 4/7\n",
      "11/11 [==============================] - 2s 154ms/step - loss: 0.7601 - accuracy: 0.7030 - val_loss: 0.5288 - val_accuracy: 0.7133\n",
      "Epoch 5/7\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 0.5562 - accuracy: 0.7576 - val_loss: 0.6542 - val_accuracy: 0.6800\n",
      "Epoch 6/7\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 0.5611 - accuracy: 0.7636 - val_loss: 0.6099 - val_accuracy: 0.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:31,173]\u001b[0m Trial 3 finished with value: 0.7133333086967468 and parameters: {'learning_rate': 0.004532289132428408, 'momentum': 0.29210806862652916, 'units': 512}. Best is trial 1 with value: 0.7644444704055786.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7410 - accuracy: 0.6848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:34,693]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9216 - accuracy: 0.6545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:38,149]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8872 - accuracy: 0.6909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:41,603]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8738 - accuracy: 0.7273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:45,113]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8784 - accuracy: 0.6485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:48,499]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9840 - accuracy: 0.5576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:52,035]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0251 - accuracy: 0.6121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:55,840]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1523 - accuracy: 0.5030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:36:59,251]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0464 - accuracy: 0.6303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:02,655]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8923 - accuracy: 0.6545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:06,039]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7450 - accuracy: 0.6424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:09,527]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8073 - accuracy: 0.6303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:12,813]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.1951 - accuracy: 0.4667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:16,156]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9201 - accuracy: 0.7091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:19,862]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0153 - accuracy: 0.5152"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:23,306]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9096 - accuracy: 0.6485"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:26,768]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - 3s 159ms/step - loss: 0.8423 - accuracy: 0.6545 - val_loss: 0.5632 - val_accuracy: 0.7200\n",
      "Epoch 2/7\n",
      "11/11 [==============================] - 2s 157ms/step - loss: 0.8356 - accuracy: 0.6182 - val_loss: 0.5093 - val_accuracy: 0.7911\n",
      "Epoch 3/7\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 0.6484 - accuracy: 0.7091 - val_loss: 0.5038 - val_accuracy: 0.7622\n",
      "Epoch 4/7\n",
      "11/11 [==============================] - 2s 152ms/step - loss: 0.7276 - accuracy: 0.6545 - val_loss: 0.4643 - val_accuracy: 0.7933\n",
      "Epoch 5/7\n",
      "11/11 [==============================] - 2s 153ms/step - loss: 0.6671 - accuracy: 0.6970 - val_loss: 0.4564 - val_accuracy: 0.8044\n",
      "Epoch 6/7\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.6758 - accuracy: 0.6909 - val_loss: 0.4179 - val_accuracy: 0.8111\n",
      "Epoch 7/7\n",
      "11/11 [==============================] - 2s 156ms/step - loss: 0.6628 - accuracy: 0.6970 - val_loss: 0.3926 - val_accuracy: 0.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:40,072]\u001b[0m Trial 20 finished with value: 0.8422222137451172 and parameters: {'learning_rate': 0.002405219201927165, 'momentum': 0.0509660878469152, 'units': 512}. Best is trial 20 with value: 0.8422222137451172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.9928 - accuracy: 0.5576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:43,478]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.0391 - accuracy: 0.4667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:47,093]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.7709 - accuracy: 0.6303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:50,931]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/7\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.8125 - accuracy: 0.6424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-01-07 06:37:54,352]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  25\n",
      "  Number of pruned trials:  21\n",
      "  Number of complete trials:  4\n",
      "Best trial:\n",
      "  Value:  0.8422222137451172\n",
      "  Params: \n",
      "    learning_rate: 0.002405219201927165\n",
      "    momentum: 0.0509660878469152\n",
      "    units: 512\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa1fbc4081ae0de2993188b2bf658a0be5bc0687"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "_uuid": "67575a4decdaf79a915d23151626b784ffa82642"
   },
   "outputs": [],
   "source": [
    "# 한번 training을 할 때 대용량 데이터를 트레이닝 한 뒤 model을 save하지 않으면 다시 처음부터\n",
    "# 트레이닝을 진행해야한다.\n",
    "model.save_weights(\"vgg.h5\") # weight를 h5 파일 포맷으로 만들어 저장하기\n",
    "                               # keras에서는 모델과 weights의 재사용을 위해 이를 파일형태로 저장하는 라이브러리를 제공하며,\n",
    "                               # 이를 통해 모델과 weights를 파일 형태로 저장하고 불러올 수가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "_uuid": "c35e70d3e1e4834dbbf840fa0ea08c049bfcd915"
   },
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"data/test\") # test에 있는 list들을 가져옴\n",
    "test_df = pd.DataFrame({                                       # 데이터프레임을 생성\n",
    "    'filename': test_filenames                                 # filename이라는 col에 test_filenames값을 가져옴\n",
    "})\n",
    "nb_samples = test_df.shape[0] # test dataset data 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "291bc3996dce8d05e174b27d64f03996d3e8038e"
   },
   "source": [
    "# Create Testing Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "_uuid": "52249ec1c35fb1be3adef386be245de3794e55aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# rescale만 해줌. (검증하는 거니까!)\n",
    "# rescale 하는 이유: 정규화 과정임. image가 0~255까지 값을 가지는 2차원 배열인데, 0~255 사이의 값을\n",
    "#                   0.0과 1.0사이의 값으로 바꾸기 위함이다.\n",
    "#                   활성화함수 및 오류역전파 알고리즘은 0.0과 1.0사이의 값을 좋아하기 때문이다.\n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    \"data/test/\", \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# shuffle을 쓰지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2fa580afca2931ec5ce374e732d8c1789d03f2ed"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "_uuid": "4782eb23fa7d003f0e2415d995894017edb2d896"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_155366/412469799.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "# test_generator 자리 : 입력 샘플의 batch를 생성하는 생성기\n",
    "# steps : 중지되기 전까지 generator로부터 얻는 단계의 총 갯수 (샘플의 batch) , np.ceil로 '올림'함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0593922e-03, 9.9894065e-01],\n",
       "       [9.8210984e-01, 1.7890163e-02],\n",
       "       [9.4376391e-01, 5.6236096e-02],\n",
       "       ...,\n",
       "       [7.4775286e-02, 9.2522472e-01],\n",
       "       [8.6558145e-01, 1.3441847e-01],\n",
       "       [9.6814903e-05, 9.9990320e-01]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1) # axis에 해당하는 값들 중 가장 큰 값의 인덱스들을 반환하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        0\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "12495    1\n",
       "12496    1\n",
       "12497    1\n",
       "12498    0\n",
       "12499    1\n",
       "Name: category, Length: 12500, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will convert the predict category back into our generator classes by using `train_generator.class_indices`. It is the classes that image generator map while converting data into computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'cat', 1: 'dog'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict((v,k) for k,v in train_generator.class_indices.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map) # test_df['category'] 값을 0 or 1을 cat or dog로 바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our prepare data part. We map data with `{1: 'dog', 0: 'cat'}`. Now we will map the result back to dog is 1 and cat is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2196.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4285.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4373.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10108.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7030.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>3522.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>7509.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>6361.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>701.jpg</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>1553.jpg</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename category\n",
       "0       2196.jpg      dog\n",
       "1       4285.jpg      cat\n",
       "2       4373.jpg      cat\n",
       "3      10108.jpg      dog\n",
       "4       7030.jpg      dog\n",
       "...          ...      ...\n",
       "12495   3522.jpg      dog\n",
       "12496   7509.jpg      dog\n",
       "12497   6361.jpg      dog\n",
       "12498    701.jpg      cat\n",
       "12499   1553.jpg      dog\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2196.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4285.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4373.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10108.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7030.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12495</th>\n",
       "      <td>3522.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12496</th>\n",
       "      <td>7509.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12497</th>\n",
       "      <td>6361.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12498</th>\n",
       "      <td>701.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>1553.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        filename  category\n",
       "0       2196.jpg         1\n",
       "1       4285.jpg         0\n",
       "2       4373.jpg         0\n",
       "3      10108.jpg         1\n",
       "4       7030.jpg         1\n",
       "...          ...       ...\n",
       "12495   3522.jpg         1\n",
       "12496   7509.jpg         1\n",
       "12497   6361.jpg         1\n",
       "12498    701.jpg         0\n",
       "12499   1553.jpg         1\n",
       "\n",
       "[12500 rows x 2 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
